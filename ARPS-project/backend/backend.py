# backend_sealion.py
"""
NutriHealth - Hackathon Edition
Fully dynamic nutrition chatbot using SEA-LION (via Ollama).

- NO hardcoded meal ideas
- NO static suggestions
- ALL responses generated by the model
- STRICT JSON output for React compatibility
- Follows hackathon rules: science-based, personalized, debunk myths
"""
from dotenv import load_dotenv

import os
import json
import requests
from typing import Any, Dict, List, Optional
from flask import Flask, request, jsonify
from flask_cors import CORS
import re

# === SEA-LION CLOUD CONFIG ==============================================
SEALION_API_URL = "https://api.sea-lion.ai/v1/chat/completions"
SEALION_API_KEY = os.getenv("SEALION_API_KEY") 
SEALION_MODEL = os.getenv(
    "SEALION_MODEL"
)

if not SEALION_API_KEY:
    print("ERROR: SEALION_API_KEY is missing from .env")

# === FLASK APP ==================================================
# Single Flask instance with CORS enabled to allow the Vite dev server
# to call these endpoints during development.

app = Flask(__name__)
CORS(app)

# add memory storage to allow bot to give relevant response
conversation_memory = []      
user_state = {                
    "goal": None,
    "dietRestrictions": None,
    "preferences": None,
    "timeAvailable": None,
    "mealPlanDuration": None,
    "calorieTarget": None,
    "proteinTarget": None
}

# add abbreviation handler 
def expand_abbreviations(text):
    """Expand common abbreviations in user messages."""
    abbreviation_map = {
        # Common abbreviations
        "dh": "don't have",
        "idk": "I don't know",
        "dc": "don't care",
        "idc": "I don't care",
        "dw": "don't want",
        "idw": "I don't want",
        "brb": "be right back",
        "btw": "by the way",
        "tbh": "to be honest",
        "imo": "in my opinion",
        "omg": "oh my god",
        "asap": "as soon as possible",
        "atm": "at the moment",
        "rn": "right now",
        "pls": "please",
        "plz": "please",
        "thx": "thanks",
        "tq": "thank you",
        "ty": "thank you",
        "np": "no problem",
        "yw": "you're welcome",
        "lol": "laughing out loud",
        "wtf": "what the f",
        "smh": "shaking my head",
        "fyi": "for your information",
        "afaik": "as far as I know",
        "tmi": "too much information",
        "nvm": "never mind",
        "jk": "just kidding",        
        
        # Nutrition specific
        "veg": "vegetarian",
        "veggie": "vegetarian",
        "gf": "gluten free",
        "df": "dairy free",
        "lf": "low fat",
        "lc": "low carb",
        "hf": "high fiber",
        "hp": "high protein",
        "bfast": "breakfast",
        "lunch": "lunch",
        "dins": "dinner",
        "snax": "snacks",
        "wt": "weight",
        "lose wt": "lose weight",
        "gain musc": "gain muscle",
        "bulk": "build muscle",
        "buff": "build muscle",
    }
    
    if not isinstance(text, str):
        return text
    
    # Convert to lowercase for matching
    lower_text = text.lower()
    
    # Check user input for exact matches first
    for abbr, full in abbreviation_map.items():
        # Match whole words only (with word boundaries)
        pattern = r'\b' + re.escape(abbr) + r'\b'
        if re.search(pattern, lower_text):
            # Replace with case preserved as much as possible
            text = re.sub(pattern, full, text, flags=re.IGNORECASE)
    
    return text

# === SYSTEM PROMPT (Hackathon-Required Behaviour) ===============
# The hackathon requires strict behavior. A helper keeps the prompt
# construction consistent wherever it is needed.

def build_system_prompt(topic: Optional[str]) -> str:
    """
    Build the guardrails SEA-LION must follow.
    No nutrition facts are hard-coded to comply with the hackathon brief.
    """

    base = f"""
You are **NutriHealth**, a nutrition-focused chatbot built for a hackathon.
You are a highly intelligent, understanding nutrition coach.
You MUST use both the conversation history and user memory to guide the user.

When users use abbreviations, understand them and respond naturally.

Here is the saved user profile:

goal: {user_state['goal']}
dietRestrictions: {user_state['dietRestrictions']}
preferences: {user_state['preferences']}
timeAvailable: {user_state['timeAvailable']}
mealPlanDuration: {user_state['mealPlanDuration']}
calorieTarget: {user_state['calorieTarget']}
proteinTarget: {user_state['proteinTarget']}

If the user says something that updates any of these,
you must update the memory in your JSON output under "memoryUpdate".

Example:
"memoryUpdate": {{ "goal": "lose weight" }}

Your required behaviour:
1. BE UNDERSTANDING of casual language, typos, and abbreviations
2. NEVER just answer. ALWAYS guide the user to the next step.
3. ALWAYS consider the user's stored goals/preferences.
4. If the user says:
   - "1 week" → store mealPlanDuration = "1 week"
   - "I want to lose weight" or "lose wt" → goal = "weight loss"
   - "I have no time" or "no time" → timeAvailable = "low"
   - "dh time" → timeAvailable = "low"
5. ALWAYS ask a relevant follow-up question.
6. ALWAYS include 3 suggestedQuestions + quickReplies   
7. Provide **clear, evidence-based** nutrition guidance.
8. **Debunk misinformation** and explain hidden science simply.
9. Give **personalized responses** based on user input.
10. Promote **healthy, sustainable habits**.
11. Speak in a **friendly, encouraging tone**.
12. ALWAYS output ONLY valid JSON - no text before or after.
13. Provide a general answer without additional guidance when the user already knows what they want or gives a direct request.
14. Be patient with users who use short/casual responses
- Use friendly, encouraging tone
- Acknowledge what the user said before asking next question
- If user uses abbreviations, show you understood by paraphrasing
- Example: User: "dh goal" → You: "I understand you don't have a specific goal yet..."

JSON FORMAT (MANDATORY):
{{
  "reply": "Your natural, friendly response here. Show understanding of abbreviations.",
  "topic": "{topic}",
  "suggestedQuestions": ["question 1", "question 2", "question 3"],
  "quickReplies": ["option 1", "option 2", "option 3"],
  "memoryUpdate": {{}}
}}
Avoid medical claims. If user mentions medical conditions, tell them to consult a professional.

Conversation focus: {topic or "general"}.
    """
    return base.strip()


# === OLLAMA CALL ================================================
# Wrap every model call so logging, payload tweaks, and future auth
# headers stay in one place.

def call_sealion(messages: List[Dict[str, str]]) -> str:
    payload = {
        "model": SEALION_MODEL,
        "messages": messages,
        "max_tokens": 350,
        "response_format": {"type": "json_object"}        
    }

    headers = {
        "Authorization": f"Bearer {SEALION_API_KEY}",
        "Content-Type": "application/json"
    }

    try:
        res = requests.post(SEALION_API_URL, headers=headers, json=payload, timeout=30)
        res.raise_for_status()
        return res.json()["choices"][0]["message"]["content"]
    except requests.exceptions.RequestException as e:
        print(f"API Request Error: {e}")
        raise
    except KeyError as e:
        print(f"API Response Error: {e}")
        raise


# === FALLBACK JSON PARSER ========================================
# SEA-LION is instructed to return JSON, but models occasionally wrap
# payloads with ``` fences. The helper below keeps the response usable.

def _strip_code_fences(raw: str) -> str:     
    if not raw:
        return None
    
    # parse json text
    try:
        return json.loads(raw)
    except json.JSONDecodeError:
        pass
    
    # define json pattern to remove ltr
    json_patterns = [
        r'```json\n(.*?)\n```', 
        r'```\n(.*?)\n```',      
        r'({.*})',               
    ]
    
    # remove json pattern
    for pattern in json_patterns:
        matches = re.findall(pattern, raw, re.DOTALL)
        if matches:
            for match in matches:
                try:
                    return json.loads(match)
                except json.JSONDecodeError:
                    continue
    
    return None


def parse_json(raw: str, fallback_topic) :
    cleaned = _strip_code_fences(raw)
    if cleaned is None:
        
        # create a structured response for fallback
        cleaned = {
            "reply": raw.strip() if raw else "How can I help you with your nutrition goals today?",
            "topic": fallback_topic,
            "suggestedQuestions": [],
            "quickReplies": [],
            "memoryUpdate": {}
        }
    
    # make sure all required fields exist
    if "reply" not in cleaned:
        cleaned["reply"] = raw.strip() if raw else "I understand. How can I help you further?"
    
    if "topic" not in cleaned:
        cleaned["topic"] = fallback_topic
    
    if "suggestedQuestions" not in cleaned:
        cleaned["suggestedQuestions"] = []
    
    if "quickReplies" not in cleaned:
        cleaned["quickReplies"] = cleaned.get("suggestedQuestions", [])[:3]
    
    if "memoryUpdate" not in cleaned:
        cleaned["memoryUpdate"] = {}
    
    # make sure arrays have at most 3 items
    cleaned["suggestedQuestions"] = cleaned["suggestedQuestions"][:3]
    cleaned["quickReplies"] = cleaned["quickReplies"][:3]
    
    # Clean reply text
    if isinstance(cleaned["reply"], str):
        cleaned["reply"] = cleaned["reply"].strip()
    
    return cleaned

# preprocess user input before sending to the model
def preprocess_user_input(text):
    if not text or not isinstance(text, str):
        return text
    
    expanded = expand_abbreviations(text)
    
    if len(expanded.split()) <= 3 and expanded.lower() in ["dh", "idk", "none", "no", "yes"]:
        return expanded
    
    return expanded

# memory storage for the model to reply relevant answer
def update_user_state_from_memory(memory_update):
    # update user state from memory update dict
    global user_state
    
    if not memory_update or not isinstance(memory_update, dict):
        return
    
    for key, value in memory_update.items():
        if key in user_state:
            user_state[key] = value
            print(f"Memory Updated: {key} → {value}")

# generate suggestion
def generate_suggestions():
    suggestions = []
    
    if user_state["goal"] is None:
        suggestions.extend(["Lose weight", "Gain muscle", "Eat healthier"])
    
    if user_state["dietRestrictions"] is None and len(suggestions) < 3:
        suggestions.extend(["Vegetarian", "No restrictions", "Gluten free"])
    
    if user_state["timeAvailable"] is None and len(suggestions) < 3:
        suggestions.extend(["Quick meals", "Meal prep", "Any time"])
    
    # fill options
    general_options = ["Meal ideas", "Recipes", "Weekly plan", "Calorie counting", "Protein goals"]
    while len(suggestions) < 3:
        for option in general_options:
            if option not in suggestions:
                suggestions.append(option)
                break
    
    return suggestions[:3]

# === API ENDPOINT ===============================================
# /api/chat handles user prompts. /api/health is a lightweight probe.

@app.route("/api/chat", methods=["POST"])
def chat():
    global conversation_memory, user_state

    try:
    # Pull the payload safely and sanitize obvious edge cases.
        data = request.get_json(force=True) 
        message = str(data.get("message", "")).strip()
        topic = data.get("topic", "general")

        if not message:
            suggestions = generate_suggestions()
            return jsonify({
                "reply": "Hi there! I'm NutriHealth, your nutrition coach. How can I help you today?",
                "topic": "welcome",
                "suggestedQuestions": ["Help me set nutrition goals", "Give me meal ideas", "Create a weekly plan"],
                "quickReplies": suggestions,
                "memoryUpdate": {}
            })
        
        # preprocess user input 
        processed_message = preprocess_user_input(message)
        print(f"User input: '{message}' → Processed: '{processed_message}'")
        
        # add original and processed messages to memory
        conversation_memory.append({"role": "user", "content": processed_message})
        conversation_memory = conversation_memory[-20:]        
        
        system_prompt = build_system_prompt(topic)

        # SEA-LION expects an OpenAI-style conversation array.
        messages = [
            {"role": "system", "content": system_prompt},
            *conversation_memory[-5:]
        ]

        # call model
        raw = call_sealion(messages)
        print(f"Model raw response: {raw[:200]}...")
        
        # parse response
        parsed = parse_json(raw, topic)

        # update memory 
        memory_update = parsed.get("memoryUpdate", {})
        update_user_state_from_memory(memory_update)
        conversation_memory.append({"role": "assistant", "content": parsed["reply"]})
        conversation_memory = conversation_memory[-20:]

        return jsonify(parsed)            
    except json.JSONDecodeError as e:
        # On failure we avoid surfacing internals to the client.
        suggestions = generate_suggestions()
        return jsonify({
            "reply": "I apologise, but I'm having trouble processing that. Could you please rephrase or try using the quick reply options below?",
            "topic": "error",
            "suggestedQuestions": ["Let's try again", "Start over", "Help me with nutrition"],
            "quickReplies": suggestions,
            "memoryUpdate": {}
        })
    except Exception as e:
        print(f"General Error: {e}")
        suggestions = generate_suggestions()
        return jsonify({
            "reply": "I'm experiencing some technical difficulties. Please try again in a moment.",
            "topic": "error",
            "suggestedQuestions": ["Try again", "Health tips", "Contact support"],
            "quickReplies": suggestions,
            "memoryUpdate": {}
        })

@app.route("/api/health", methods=["GET"])
def health():
    # Basic readiness endpoint for render hosts and manual checks.
    return jsonify({
        "status": "ok",
        "model": SEALION_MODEL,
        "memoryStored": user_state,
        "conversationLength": len(conversation_memory)
    })

if __name__ == "__main__":
    # Development server only; production should use a WSGI container.
    app.run(host="0.0.0.0", port=5000, debug=True)